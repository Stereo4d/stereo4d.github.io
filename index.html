<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="description" content="Stereo4D" />
    <meta name="keywords" content="Stereo4D" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Stereo4D</title>

    <link rel="icon" type="image/x-icon" href="static/stereo_icon.ico" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
    <script>
      window.dataLayer = window.dataLayer || [];

      function gtag() {
        dataLayer.push(arguments);
      }

      gtag("js", new Date());

      gtag("config", "G-PYVRSFMDRL");
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans:400,600|Noto+Sans:ital,wght@0,400;0,600;1,400;1,600|Castoro:400,600" rel="stylesheet" />

    <link rel="stylesheet" href="./static/css/index.css" />
    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="./static/css/slider.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />

    <link rel="stylesheet" href="./static/css/app.css" />
    <link rel="stylesheet" href="./static/css/stack_video.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/index.js"></script>
    <!-- <script src="./static/js/stack_video.js"></script> -->

    <style>
      #interactive {
        position: relative;
        display: inline-block;
        width: 768px;
        aspect-ratio: 16/9;
        max-width: 100%;
      }
      #interactive canvas,
      #interactive svg,
      #interactive #glfailed {
        display: block;
        position: absolute;
        width: 100%;
        height: 100%;
        touch-action: none;
      }
      #interactive svg {
        pointer-events: none;
      }
      #interactive #glfailed {
        color: #f88;
        background: black;
        display: none;
      }
      .load img {
        width: 128px;
        height: 72px;
        margin-right: 4px;
      }
    </style>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1
                class="title is-1 publication-title"
                style="margin-bottom: 0rem"
              >
                Stereo4D
              </h1>
              <h3 class="title is-3 publication-title">
                Learning How Things Move in 3D from Internet Stereo Videos
              </h3>
              <div class="is-size-6 publication-authors">
                <span class="author-block">
                  <a href="https://jinlinyi.github.io/">Linyi Jin</a
                  ><sup>1,2</sup></span
                >&nbsp&nbsp&nbsp&nbsp
                <span class="author-block">
                  <a
                    href="https://scholar.google.com/citations?user=IkpNZAoAAAAJ&hl=en"
                    >Richard Tucker</a
                  ><sup>1</sup>&nbsp&nbsp&nbsp&nbsp
                </span>
                <span class="author-block">
                  <a href="https://zhengqili.github.io/">Zhengqi Li</a
                  ><sup>1</sup>&nbsp&nbsp&nbsp&nbsp
                </span>
                <span class="author-block">
                  <a href="https://cs.nyu.edu/~fouhey/">David Fouhey</a
                  ><sup>3</sup>&nbsp&nbsp&nbsp&nbsp
                </span>
                <span class="author-block">
                  <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a
                  ><sup>1*</sup>&nbsp&nbsp&nbsp&nbsp
                </span>
                <span class="author-block">
                  <a href="https://holynski.org/">Aleksander Hołyński</a
                  ><sup>1,4*</sup>
                </span>
              </div>

              <div class="is-size-6 publication-authors">
                <span class="author-block"><sup>1</sup>Google DeepMind</span>
                &nbsp&nbsp&nbsp&nbsp
                <span class="author-block"
                  ><sup>2</sup>University of Michigan</span
                >
                &nbsp&nbsp&nbsp&nbsp
                <span class="author-block"
                  ><sup>3</sup>New York University</span
                >
                &nbsp&nbsp&nbsp&nbsp
                <span class="author-block"><sup>4</sup>UC Berkeley</span>
                &nbsp&nbsp&nbsp&nbsp (*: equal contribution)
              </div>
              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a
                      href=""
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      class="external-link button is-normal is-rounded is-dark"
                      disabled
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Check back for code & data updates</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-centered is-four-fifths rounded">
              <div
                class="notification is-info"
                style="
                  text-align: center;
                  padding-bottom: 5px;
                  padding-top: 5px;
                "
              >
                <h6 style="text-align: center; color: rgb(0, 0, 0)">
                  <strong>TL;DR</strong>: Use stereo videos from the internet to create a dataset of over 100,000 real-world 4D scenes
                  with <em>metric scale</em> and <em>long-term 3D motion trajectories</em>.
                </h6>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-light is-small">
      <div class="hero-body nopadding has-text-centered container is-max-desktop">
        <h2 class="title is-3 has-text-centered" style="margin-bottom: 5px">
          Dataset gallery
        </h2> 
          Examples from our processed dataset, showing a wide variety of scenes
          and moving objects. Color trails are only shown for moving points, but
          all points have been reconstructed in 3D.<br><br>
        <div class="container is-max-desktop">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-fullbody">
              <!-- ko2x2dcU9PI-clip13 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/ko2x2dcU9PI-clip13-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- HgkMYtMSdW4-clip8 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/HgkMYtMSdW4-clip8-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- 3VDtiWBLdMY-clip11 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/3VDtiWBLdMY-clip11-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- QaDjmWNVS18-clip55 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/QaDjmWNVS18-clip55-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- Xe3hmWN3Qp8-clip75 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/Xe3hmWN3Qp8-clip75-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- CMwZrkhQ0ck-clip28 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/CMwZrkhQ0ck-clip28-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- 7YAIbIXy67Y-clip30 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/7YAIbIXy67Y-clip30-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- 207Wvni3ujI-clip9 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/207Wvni3ujI-clip9-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- 7pxhAFrmIQs-clip9 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/7pxhAFrmIQs-clip9-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- C7ZKYUMpPz4-clip30 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/C7ZKYUMpPz4-clip30-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- 7thep44_zto-clip13 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/7thep44_zto-clip13-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- n6fNculviyQ-clip19 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/n6fNculviyQ-clip19-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- y1e-TwNNiiQ-clip2 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/y1e-TwNNiiQ-clip2-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            
            <div class="item item-fullbody">
              <!-- Lqhj6rCE6E0-clip5 -->
              <div class="item">
                <video autoplay muted loop playsinline>
                  <source src="static/videos/stereo4d-gallery/composite/Lqhj6rCE6E0-clip5-composited.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <!-- <center>
            <video id="teaser" autoplay muted loop playsinline width="90%">
              <source src="static/videos/teaser.mp4" type="video/mp4" />
            </video>
          </center> -->
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Learning to understand dynamic 3D scenes from imagery is crucial
                for applications ranging from robotics to scene reconstruction.
                Yet, unlike other problems where large-scale supervised training
                has enabled rapid progress, directly supervising methods for
                recovering 3D motion remains challenging due to the fundamental
                difficulty of obtaining ground truth annotations. We present a
                system for mining high-quality 4D reconstructions from internet
                stereoscopic, wide-angle videos. Our system fuses and filters
                the outputs of camera pose estimation, stereo depth estimation,
                and temporal tracking methods into high-quality dynamic 3D
                reconstructions. We use this method to generate large-scale data
                in the form of world-consistent, pseudo-metric 3D point clouds
                with long-term motion trajectories. We demonstrate the utility
                of this data by training a variant of DUSt3R to predict
                structure and 3D motion from real-world image pairs, showing
                that training on our reconstructed data enables generalization
                to diverse real-world scenes.
              </p>
            </div>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </section>

    <section>
      <div class="container is-max-desktop">
        <!-- Pipeline. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="notification is-info is-light">
              <h2 class="title is-3">How is it made?</h2>
              <div class="content has-text-justified">
                <p>
                  Stereoscopic fisheye videos from the internet are an untapped
                  source of high-quality 4D data: (1) there are hundreds of
                  thousands of them, and (2) since they're designed to capture
                  immersive VR experiences, they have wide field-of-view stereo
                  imagery with a standardized stereo baseline, precisely the
                  kind of information that's useful in reconstructing
                  pseudo-metric 4D scenes. These videos contain a pretty even
                  spread of what we might see in everyday life&mdash;some
                  examples are shown here:
                </p>
                <center style="display: flex; align-items: center">
                  <div>
                    <img id="pic1" src="static/videos/pipeline/vrcameras.png" />
                  </div>
                  <video
                    id="pipeline"
                    autoplay
                    muted
                    loop
                    playsinline
                    width="82%"
                  >
                    <source
                      src="static/videos/pipeline/vr180s-v2_compressed.mp4"
                      type="video/mp4"
                    />
                  </video>
                </center>
              </div>
              <div class="content has-text-justified">
                <p>
                  We process these videos with a careful combination of
                  state-of-the-art methods for (1) stereo depth estimation, (2)
                  2D point tracking, as well as (3) a stereo structure-from-motion
                  system optimized for dynamic stereo videos. From these
                  methods, we can extract per-frame camera poses, per-pixel
                  pseudo-metric depth from stereo disparity, and long-term 2D
                  point tracks.
                </p>
                <center style="display: flex; align-items: center">
                  <video
                    id="pipeline_stage1"
                    autoplay
                    muted
                    loop
                    playsinline
                    width="35%"
                  >
                    <source
                      src="static/videos/pipeline/input_equirect_compressed.mp4"
                      type="video/mp4"
                    />
                  </video>
                  <div style="margin: 0.1rem">
                    <img src="static/videos/pipeline/arrow.png" />
                  </div>
                  <div>
                    <div
                      style="
                        display: flex;
                        justify-content: space-around;
                        color: black;
                        font-size: 0.7rem;
                      "
                    >
                      <span>Camera poses</span> <span>Per frame depth</span>
                      <span>2D tracks</span>
                    </div>
                    <video autoplay muted loop playsinline width="100%">
                      <source
                        src="static/videos/pipeline/intermediate_output_compressed.mp4"
                        type="video/mp4"
                      />
                    </video>
                  </div>
                </center>
              </div>
              <div class="content has-text-justified">
                <p>
                  We then fuse these quantities into 4D reconstructions, by
                  lifting the 2D tracks into 3D with their depth, and aligning
                  all the scene content by compensating for the known camera
                  motion. This results in temporally consistent, high-quality
                  dynamic reconstructions, with long-term correspondence over
                  time.
                </p>
                <center>
                  <video
                    id="pipeline_3d"
                    autoplay
                    muted
                    loop
                    playsinline
                    width="100%"
                  >
                    <source
                      src="static/videos/pipeline/9F_CaOaT9Xg-clip0-dyna_3dtrack_concated.mp4"
                      type="video/mp4"
                    />
                  </video>
                </center>
              </div>

              <div class="content has-text-justified">
                <p>
                  This gives us pretty reasonable 4D scenes, but there's still
                  work left to be done. The precision of stereo depth
                  predictions may be limited by the content of the scene (e.g.,
                  distant objects seen with small parallax may have a large
                  variance of possible depth values&mdash;and can therefore vary
                  signifcantly from one frame to another). This results in
                  jittery or noisy 3D tracks. To compensate for this, we
                  additionally perform an optimization process over the 3D
                  trajectories that removes this noise.
                </p>
              </div>
              <div class="columns is-centered is-vcentered">
                <div class="column is-two-fifths">
                  <!-- Left Video -->
                  <video
                    class="syncstart"
                    muted
                    loop
                    playsinline
                    preload="auto"
                  >
                    <source
                      src="static/videos/track_optimization/crop-OHBI-441e00-clip23-2d-fix.mp4"
                      type="video/mp4"
                    />
                  </video>
                  <span style="color: black; font-size: 1rem"
                    >Projected Tracks</span
                  >
                </div>
                <div class="column is-three-fifths">
                  <!-- Slider Comparison -->
                  <div class="image-comparison">
                    <div class="images-container">
                      <video
                        class="before-image syncstart"
                        muted
                        loop
                        playsinline
                        preload="auto"
                      >
                        <source
                          src="static/videos/track_optimization/after3.mp4"
                          type="video/mp4"
                        />
                      </video>
                      <video
                        class="after-image syncstart"
                        muted
                        loop
                        playsinline
                        preload="auto"
                      >
                        <source
                          src="static/videos/track_optimization/before3.mp4"
                          type="video/mp4"
                        />
                      </video>
                      <div class="slider-line"></div>
                      <div class="slider-icon">
                        <svg
                          xmlns="http://www.w3.org/2000/svg"
                          fill="none"
                          viewBox="0 0 24 24"
                          stroke-width="1.5"
                          stroke="currentColor"
                          class="w-6 h-6"
                        >
                          <path
                            stroke-linecap="round"
                            stroke-linejoin="round"
                            d="M8.25 15L12 18.75 15.75 15m-7.5-6L12 5.25 15.75 9"
                          />
                        </svg>
                      </div>
                      <input type="range" class="slider" min="1" max="99" />
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
        <!--/ Pipeline. -->
      </div>
    </section>
    <br /> <br>
    <section class="">
      <div class="container is-max-desktop">
        <div class="hero-body nopadding">
          <div
            class="columns is-centered has-text-centered"
            id="dynadust3r_result"
          >
            <div class="column is-four-fifths">
              <h2 class="title is-3">
                Using this data to learn <em>how things move</em>
              </h2>

              <div class="content has-text-justified">
                <p>
                  To validate that our dataset is useful for learning about the
                  structure and motion of real-world scenes, we use it to train
                  a variant of
                  <a href="https://dust3r.europe.naverlabs.com/">DUSt3R</a>.
                  DUSt3R usually takes as input a pair of images, and predicts a
                  3D point for each pixel in both
                  images (in a shared coordinate frame)&mdash;but it fails when the scene is dynamic, e.g.,
                  when there is scene motion between the two images. This comes
                  largely as a consequence of the fact that DUSt3R is trained on
                  static data (since there aren't very many sources of
                  ground-truth dynamic 3D scenes). We extend DUSt3R by adding a
                  notion of time&mdash;into a model that we call DynaDUSt3R, and
                  train it on our Stereo4D dataset. Given a pair of frames from
                  any real-world video, DynaDUSt3R predicts per-pixel 3D points
                  for each frame, as well as the 3D motion trajectories that
                  connect them in time.
                </p>
		<p>
		  Click on the different examples below to see
		  predicted shape and motion from various image pairs.
		</p>
                <center>
                  <table
                    style="margin-left: auto; margin-right: auto; width: 100%"
                  >
                    <tr>
                      <th style="text-align: center; width: 30%; border: none">
                        Input image pair
                      </th>
                      <th style="text-align: center; width: 70%; border: none">
                        Reconstruction
                      </th>
                    </tr>
                    <tr>
                      <td style="text-align: center; width: 37%">
                        <img
                          class="card-img"
                          id="dynadust3r_input"
                          src="static/videos/dynadust3r/cow/input.gif"
                        />
                      </td>
                      <td rowspan="1" colspan="2" style="width: 63%">
                        <video
                          id="dynadust3r_prediction"
                          class="video"
                          width="100%"
                          loop
                          playsinline
                          autoplay
                          muted
                          controls
                          style="aspect-ratio: 16/9"
                        >
                          <source
                            src="static/videos/dynadust3r/cow/cow_fixed_horizon-fix_compressed.mp4"
                          />
                        </video>
                      </td>
                    </tr>
                  </table>

                  <div
                    class="pill-row scene-pills"
                    id="cameratime-pills"
                    role="group"
                    aria-relevant="additions text"
                  >
                    <div class="pill scene-pill" data-value="cow">
                      <img
                        class="card-img"
                        src="static/videos/dynadust3r/cow/rgb_00000.png"
                      />
                    </div>
                    <div class="pill scene-pill" data-value="park">
                      <img
                        class="card-img"
                        src="static/videos/dynadust3r/park/rgb_00000.png"
                      />
                    </div>
                    <div class="pill scene-pill" data-value="rolling">
                      <img
                        class="card-img"
                        src="static/videos/dynadust3r/rolling/rgb_00000.png"
                      />
                    </div>
                    <div class="pill scene-pill" data-value="dog_on_field">
                      <img
                        class="card-img"
                        src="static/videos/dynadust3r/dog_on_field/rgb_00000.png"
                      />
                    </div>
                    <div class="pill scene-pill" data-value="exhibition">
                      <img
                        class="card-img"
                        src="static/videos/dynadust3r/exhibition/rgb_00000.png"
                      />
                    </div>
                    <div class="pill scene-pill" data-value="guitar">
                      <img
                        class="card-img"
                        src="static/videos/dynadust3r/guitar/rgb_00000.png"
                      />
                    </div>
                    <div class="pill scene-pill" data-value="museum">
                      <img
                        class="card-img"
                        src="static/videos/dynadust3r/museum/rgb_00000.png"
                      />
                    </div>
                  </div>
                </center>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <br />
    <section class="section" id="Acknowledgements">
      <div class="container is-max-desktop">
        <div class="hero-body nopadding">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths is-centered">
              <br /><br />
              <h2 class="title is-3">Acknowledgements</h2>
              <div class="content has-text-justified">
                <font size="3">
                  Thanks to Jon Barron, Ruiqi Gao, Kyle Genova, Philipp Henzler, Erika Lu, Andrew Liu, Qianqian Wang, Rundi Wu, and Richard Szeliski for their helpful proofreading, comments, and discussions. 
                  Thanks to Carl Doersch, Skanda Koppula, and Ignacio Rocco for their assistance with TAPVid-3D and BootsTAP. 
                  Thanks to Carlos Hernandez, Janne Kontkanen, Dominik Kaeser, Ricardo Martin-Brualla, and Changchang Wu for their help with VR180 cameras and videos.
                </font>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <br />

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{jin2024_Stereo4d,
  title  = {Stereo4D: Learning How Things Move in 3D from Internet Stereo Videos},
  author = {Jin, Linyi and Tucker, Richard and Li, Zhengqi and Fouhey, David and Snavely, Noah and Holynski, Aleksander},
  year   = {2024}
}</code></pre>
      </div>
    </section>

    <footer class="footer">
      <div align="center" class="container">
        <div class="columns is-centered">
          <div class="content">
            This website is borrowed from
            <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a> and <a href="https://cat3d.github.io/">CAT3D</a>
          </div>
        </div>
      </div>
    </footer>
    <script src="./static/js/slider.js"></script>
    <script src="./static/js/dust3r_selection.js"></script>
  </body>
</html>
